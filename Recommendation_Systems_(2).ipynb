{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi0lGIP1nYnP",
        "outputId": "1327d341-dc37-4167-b9a4-d730099e6e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Numpy version: 1.26.4\n",
            "Pandas version: 2.3.0+4.g1dfc98e16a\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries for recommendation systems\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Surprise library for collaborative filtering\n",
        "from surprise import Dataset, Reader, SVD, NMF, KNNBasic, accuracy\n",
        "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "\n",
        "# Note: Make sure you have the following packages installed in your environment:\n",
        "# pip install scikit-surprise numpy pandas scipy\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Numpy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8dNgH2iK9KQ",
        "outputId": "f01b3a27-e532-462d-9b29-8d6ffe4eda37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading MovieLens 100k dataset...\n",
            "âœ… MovieLens 100k dataset loaded successfully!\n",
            "ğŸ“Š Dataset contains 100,000 ratings\n",
            "ğŸ“ Dataset saved to: ~/.surprise_data/ml-100k/\n"
          ]
        }
      ],
      "source": [
        "# Load the MovieLens 100k dataset\n",
        "# Force download by using the download parameter directly\n",
        "import os\n",
        "import sys\n",
        "from unittest.mock import patch\n",
        "\n",
        "print(\"Loading MovieLens 100k dataset...\")\n",
        "\n",
        "# Use mock to automatically respond 'Y' to the download prompt\n",
        "with patch('builtins.input', return_value='Y'):\n",
        "    try:\n",
        "        data = Dataset.load_builtin('ml-100k')\n",
        "        print(\"âœ… MovieLens 100k dataset loaded successfully!\")\n",
        "        print(f\"ğŸ“Š Dataset contains {len(data.raw_ratings):,} ratings\")\n",
        "        print(f\"ğŸ“ Dataset saved to: ~/.surprise_data/ml-100k/\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading dataset: {e}\")\n",
        "        print(\"Make sure scikit-surprise is installed: pip install scikit-surprise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "innI5O7pnTy5",
        "outputId": "0cb75a58-8634-4cff-ea30-acd2bea07e91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('196', '242', 3.0, '881250949'),\n",
              " ('186', '302', 3.0, '891717742'),\n",
              " ('22', '377', 1.0, '878887116'),\n",
              " ('244', '51', 2.0, '880606923'),\n",
              " ('166', '346', 1.0, '886397596'),\n",
              " ('298', '474', 4.0, '884182806'),\n",
              " ('115', '265', 2.0, '881171488'),\n",
              " ('253', '465', 5.0, '891628467'),\n",
              " ('305', '451', 3.0, '886324817'),\n",
              " ('6', '86', 3.0, '883603013')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.raw_ratings[:10]\n",
        "# (user_id, movie_id, rating, timestamp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GxoUn7kmtKaN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 75000 ratings\n",
            "Test set: 25000 ratings\n",
            "Training set info:\n",
            "  - Number of users: 943\n",
            "  - Number of items: 1644\n",
            "  - Rating scale: (1, 5)\n",
            "  - Global mean rating: 3.53\n"
          ]
        }
      ],
      "source": [
        "# Split data into train and test sets (75% train, 25% test)\n",
        "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
        "\n",
        "# Trainset objects don't have len(), but they have n_ratings attribute\n",
        "print(f\"Training set: {trainset.n_ratings} ratings\")\n",
        "print(f\"Test set: {len(testset)} ratings\")\n",
        "\n",
        "# Additional information about the split\n",
        "print(f\"Training set info:\")\n",
        "print(f\"  - Number of users: {trainset.n_users}\")\n",
        "print(f\"  - Number of items: {trainset.n_items}\")\n",
        "print(f\"  - Rating scale: {trainset.rating_scale}\")\n",
        "print(f\"  - Global mean rating: {trainset.global_mean:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VuBOAkQDtabt"
      },
      "outputs": [],
      "source": [
        "# Access trainset object which contains user-item interactions\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "# Total number of users and items\n",
        "n_users = trainset.n_users\n",
        "n_items = trainset.n_items\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5_u_jckxvqkz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set information:\n",
            "Number of users: 943\n",
            "Number of items: 1682\n",
            "Number of ratings: 100000\n",
            "Rating scale: (1, 5)\n",
            "Global mean rating: 3.53\n",
            "\n",
            "Sample interactions (user_id, item_id, rating):\n",
            "User 0, Item 0, Rating 3.0\n",
            "User 0, Item 528, Rating 4.0\n",
            "User 0, Item 377, Rating 4.0\n",
            "User 0, Item 522, Rating 3.0\n",
            "User 0, Item 431, Rating 5.0\n",
            "User 0, Item 834, Rating 5.0\n",
            "User 0, Item 380, Rating 4.0\n",
            "User 0, Item 329, Rating 4.0\n",
            "User 0, Item 550, Rating 5.0\n",
            "User 0, Item 83, Rating 4.0\n"
          ]
        }
      ],
      "source": [
        "# Display information about the training set\n",
        "print(f\"Training set information:\")\n",
        "print(f\"Number of users: {trainset.n_users}\")\n",
        "print(f\"Number of items: {trainset.n_items}\")\n",
        "print(f\"Number of ratings: {trainset.n_ratings}\")\n",
        "print(f\"Rating scale: {trainset.rating_scale}\")\n",
        "print(f\"Global mean rating: {trainset.global_mean:.2f}\")\n",
        "\n",
        "# Show some sample user-item interactions\n",
        "sample_interactions = list(trainset.all_ratings())[:10]\n",
        "print(f\"\\nSample interactions (user_id, item_id, rating):\")\n",
        "for interaction in sample_interactions:\n",
        "    print(f\"User {interaction[0]}, Item {interaction[1]}, Rating {interaction[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2FstqauZuOr2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating user-item interaction matrix...\n",
            "Interaction matrix shape: (943, 1682)\n",
            "Number of non-zero entries: 100000\n",
            "Sparsity: 93.70%\n",
            "\n",
            "First 10x10 portion of the interaction matrix:\n",
            "[[3. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 3. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 3. 0. 4. 0.]\n",
            " [0. 0. 0. 2. 0. 0. 4. 0. 4. 4.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 4. 4. 4. 0. 0.]\n",
            " [0. 4. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 5. 0. 0.]\n",
            " [5. 4. 0. 0. 0. 5. 0. 0. 3. 4.]\n",
            " [4. 4. 0. 0. 0. 5. 0. 1. 0. 3.]]\n"
          ]
        }
      ],
      "source": [
        "# Create user-item interaction matrix (sparse format for memory efficiency)\n",
        "print(\"Creating user-item interaction matrix...\")\n",
        "\n",
        "# Initialize data arrays for sparse matrix creation\n",
        "row_indices = []\n",
        "col_indices = []\n",
        "ratings = []\n",
        "\n",
        "# Collect all user-item-rating triplets\n",
        "for (u, i, rating) in trainset.all_ratings():\n",
        "    row_indices.append(u)\n",
        "    col_indices.append(i)\n",
        "    ratings.append(rating)\n",
        "\n",
        "# Create sparse matrix\n",
        "interaction_matrix = csr_matrix((ratings, (row_indices, col_indices)), \n",
        "                               shape=(n_users, n_items))\n",
        "\n",
        "print(f\"Interaction matrix shape: {interaction_matrix.shape}\")\n",
        "print(f\"Number of non-zero entries: {interaction_matrix.nnz}\")\n",
        "print(f\"Sparsity: {(1 - interaction_matrix.nnz / (n_users * n_items)) * 100:.2f}%\")\n",
        "\n",
        "# Display a small portion of the matrix (first 10x10)\n",
        "print(f\"\\nFirst 10x10 portion of the interaction matrix:\")\n",
        "print(interaction_matrix[:10, :10].toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eaxwdcYXuPtu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interaction matrix shape: (943, 1682)\n",
            "Matrix dimensions: 943 users Ã— 1682 items\n",
            "Total possible interactions: 1,586,126\n",
            "Actual interactions: 100,000\n",
            "Matrix density: 6.3047%\n",
            "\n",
            "Memory usage:\n",
            "Dense matrix would use: 12.10 MB\n",
            "Sparse matrix uses: 1.15 MB\n",
            "Memory saving: 90.51%\n"
          ]
        }
      ],
      "source": [
        "# Interaction matrix analysis\n",
        "print(f\"Interaction matrix shape: {interaction_matrix.shape}\")\n",
        "print(f\"Matrix dimensions: {n_users} users Ã— {n_items} items\")\n",
        "print(f\"Total possible interactions: {n_users * n_items:,}\")\n",
        "print(f\"Actual interactions: {interaction_matrix.nnz:,}\")\n",
        "print(f\"Matrix density: {(interaction_matrix.nnz / (n_users * n_items)) * 100:.4f}%\")\n",
        "\n",
        "# Memory usage estimation\n",
        "memory_dense = n_users * n_items * 8  # 8 bytes per float64\n",
        "memory_sparse = interaction_matrix.data.nbytes + interaction_matrix.indices.nbytes + interaction_matrix.indptr.nbytes\n",
        "print(f\"\\nMemory usage:\")\n",
        "print(f\"Dense matrix would use: {memory_dense / 1024**2:.2f} MB\")\n",
        "print(f\"Sparse matrix uses: {memory_sparse / 1024**2:.2f} MB\")\n",
        "print(f\"Memory saving: {((memory_dense - memory_sparse) / memory_dense) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tTu0Hy_bvKH9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SVD model...\n",
            "SVD model training completed!\n",
            "Making predictions on test set...\n",
            "\n",
            "Model Evaluation:\n",
            "RMSE: 0.6757\n",
            "MAE:  0.5339\n",
            "\n",
            "Summary:\n",
            "RMSE: 0.6757\n",
            "MAE: 0.5339\n"
          ]
        }
      ],
      "source": [
        "# SVD (Singular Value Decomposition) Collaborative Filtering\n",
        "print(\"Training SVD model...\")\n",
        "\n",
        "# Initialize the SVD algorithm with default parameters\n",
        "algo = SVD(random_state=42)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)\n",
        "print(\"SVD model training completed!\")\n",
        "\n",
        "# Predict ratings for the testset\n",
        "print(\"Making predictions on test set...\")\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Evaluate the model using RMSE and MAE\n",
        "print(\"\\nModel Evaluation:\")\n",
        "rmse_score = accuracy.rmse(predictions, verbose=True)\n",
        "mae_score = accuracy.mae(predictions, verbose=True)\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"RMSE: {rmse_score:.4f}\")\n",
        "print(f\"MAE: {mae_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bwZcqYXIvttd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample predictions (User ID, Item ID, Actual Rating, Predicted Rating, Details):\n",
            "--------------------------------------------------------------------------------\n",
            " 1. User 391, Item 591, Actual: 4.0, Predicted:  3.54, Error:  0.46\n",
            " 2. User 181, Item 1291, Actual: 1.0, Predicted:  1.00, Error:  0.00\n",
            " 3. User 637, Item 268, Actual: 2.0, Predicted:  2.42, Error:  0.42\n",
            " 4. User 332, Item 451, Actual: 5.0, Predicted:  4.45, Error:  0.55\n",
            " 5. User 271, Item 204, Actual: 4.0, Predicted:  3.74, Error:  0.26\n",
            " 6. User  27, Item 286, Actual: 3.0, Predicted:  3.43, Error:  0.43\n",
            " 7. User 387, Item 663, Actual: 4.0, Predicted:  4.08, Error:  0.08\n",
            " 8. User  92, Item 722, Actual: 3.0, Predicted:  2.91, Error:  0.09\n",
            " 9. User 820, Item 347, Actual: 4.0, Predicted:  3.43, Error:  0.57\n",
            "10. User 479, Item 1444, Actual: 1.0, Predicted:  2.04, Error:  1.04\n",
            "\n",
            "Prediction Statistics:\n",
            "Actual ratings - Mean: 3.53, Std: 1.13\n",
            "Predicted ratings - Mean: 3.53, Std: 0.73\n",
            "Min predicted rating: 1.00\n",
            "Max predicted rating: 5.00\n"
          ]
        }
      ],
      "source": [
        "# Display sample predictions\n",
        "print(\"Sample predictions (User ID, Item ID, Actual Rating, Predicted Rating, Details):\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for i, pred in enumerate(predictions[:10]):\n",
        "    print(f\"{i+1:2d}. User {pred.uid:>3}, Item {pred.iid:>3}, \"\n",
        "          f\"Actual: {pred.r_ui:>3.1f}, Predicted: {pred.est:>5.2f}, \"\n",
        "          f\"Error: {abs(pred.r_ui - pred.est):>5.2f}\")\n",
        "\n",
        "# Calculate prediction statistics\n",
        "actual_ratings = [pred.r_ui for pred in predictions]\n",
        "predicted_ratings = [pred.est for pred in predictions]\n",
        "\n",
        "print(f\"\\nPrediction Statistics:\")\n",
        "print(f\"Actual ratings - Mean: {np.mean(actual_ratings):.2f}, Std: {np.std(actual_ratings):.2f}\")\n",
        "print(f\"Predicted ratings - Mean: {np.mean(predicted_ratings):.2f}, Std: {np.std(predicted_ratings):.2f}\")\n",
        "print(f\"Min predicted rating: {min(predicted_ratings):.2f}\")\n",
        "print(f\"Max predicted rating: {max(predicted_ratings):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WWFlD9ojvxbl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Making prediction for User 196 and Item 302:\n",
            "\n",
            "Prediction Details:\n",
            "User ID: 196\n",
            "Item ID: 302\n",
            "Predicted Rating: 4.043\n",
            "Prediction Impossible: False\n",
            "User 196 exists in training data\n",
            "Item 302 exists in training data\n"
          ]
        }
      ],
      "source": [
        "# Predict the rating for a specific user and item\n",
        "user_id = str(196)  # user_id should be a string\n",
        "item_id = str(302)  # item_id should be a string\n",
        "\n",
        "print(f\"Making prediction for User {user_id} and Item {item_id}:\")\n",
        "predicted_rating = algo.predict(user_id, item_id)\n",
        "\n",
        "print(f\"\\nPrediction Details:\")\n",
        "print(f\"User ID: {predicted_rating.uid}\")\n",
        "print(f\"Item ID: {predicted_rating.iid}\")\n",
        "print(f\"Predicted Rating: {predicted_rating.est:.3f}\")\n",
        "print(f\"Prediction Impossible: {predicted_rating.details['was_impossible']}\")\n",
        "\n",
        "# Check if this user-item pair was in training data\n",
        "try:\n",
        "    actual_rating = trainset.to_raw_uid(trainset.to_inner_uid(user_id))\n",
        "    print(f\"User {user_id} exists in training data\")\n",
        "except:\n",
        "    print(f\"User {user_id} is new (not in training data)\")\n",
        "\n",
        "try:\n",
        "    actual_item = trainset.to_raw_iid(trainset.to_inner_iid(item_id))\n",
        "    print(f\"Item {item_id} exists in training data\")\n",
        "except:\n",
        "    print(f\"Item {item_id} is new (not in training data)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TTuBkbeHwB9s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training KNN model with item-based collaborative filtering...\n",
            "Computing item-item similarity matrix...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "KNN model training completed!\n",
            "Making predictions with KNN model...\n",
            "\n",
            "KNN Model Evaluation:\n",
            "RMSE: 0.8887\n",
            "MAE:  0.6891\n",
            "\n",
            "KNN Summary:\n",
            "RMSE: 0.8887\n",
            "MAE: 0.6891\n",
            "\n",
            "Model Comparison:\n",
            "SVD  - RMSE: 0.6757, MAE: 0.5339\n",
            "KNN  - RMSE: 0.8887, MAE: 0.6891\n"
          ]
        }
      ],
      "source": [
        "# KNN-based Collaborative Filtering (Item-based)\n",
        "print(\"Training KNN model with item-based collaborative filtering...\")\n",
        "\n",
        "# Configure similarity options for item-based filtering\n",
        "sim_options = {\n",
        "    'name': 'cosine',        # similarity metric: cosine similarity\n",
        "    'user_based': False,     # False = item-based filtering, True = user-based\n",
        "    'min_support': 5,        # minimum number of common items for similarity calculation\n",
        "    'shrinkage': 100         # shrinkage parameter to avoid overfitting\n",
        "}\n",
        "\n",
        "# Initialize the KNN algorithm\n",
        "knn_algo = KNNBasic(k=40, sim_options=sim_options, random_state=42)\n",
        "print(\"Computing item-item similarity matrix...\")\n",
        "\n",
        "# Train the algorithm (this will compute the similarity matrix)\n",
        "knn_algo.fit(trainset)\n",
        "print(\"KNN model training completed!\")\n",
        "\n",
        "# Test the algorithm on the testset\n",
        "print(\"Making predictions with KNN model...\")\n",
        "knn_predictions = knn_algo.test(testset)\n",
        "\n",
        "# Evaluate the KNN model\n",
        "print(\"\\nKNN Model Evaluation:\")\n",
        "knn_rmse = accuracy.rmse(knn_predictions, verbose=True)\n",
        "knn_mae = accuracy.mae(knn_predictions, verbose=True)\n",
        "\n",
        "print(f\"\\nKNN Summary:\")\n",
        "print(f\"RMSE: {knn_rmse:.4f}\")\n",
        "print(f\"MAE: {knn_mae:.4f}\")\n",
        "\n",
        "# Compare with SVD\n",
        "print(f\"\\nModel Comparison:\")\n",
        "print(f\"SVD  - RMSE: {rmse_score:.4f}, MAE: {mae_score:.4f}\")\n",
        "print(f\"KNN  - RMSE: {knn_rmse:.4f}, MAE: {knn_mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ql-ooV2bwJ-9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting hyperparameter tuning for SVD...\n",
            "This may take several minutes...\n",
            "Testing 16 parameter combinations...\n",
            "\n",
            "Grid Search Results:\n",
            "==================================================\n",
            "Best RMSE score: 0.9340\n",
            "Best MAE score: 0.7400\n",
            "\n",
            "Best parameters (RMSE):\n",
            "  n_factors: 100\n",
            "  n_epochs: 30\n",
            "  lr_all: 0.005\n",
            "  reg_all: 0.1\n",
            "\n",
            "Best parameters (MAE):\n",
            "  n_factors: 100\n",
            "  n_epochs: 30\n",
            "  lr_all: 0.005\n",
            "  reg_all: 0.1\n",
            "\n",
            "Training final model with best parameters...\n",
            "\n",
            "Optimized Model Performance:\n",
            "RMSE: 0.8343\n",
            "MAE: 0.6619\n",
            "\n",
            "Improvement over default SVD:\n",
            "RMSE improvement: -23.46%\n",
            "MAE improvement: -23.96%\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter Tuning with Grid Search\n",
        "print(\"Starting hyperparameter tuning for SVD...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Define a smaller parameter grid for faster execution\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100],      # Number of latent factors\n",
        "    'n_epochs': [20, 30],        # Number of training epochs\n",
        "    'lr_all': [0.002, 0.005],    # Learning rate\n",
        "    'reg_all': [0.02, 0.1]       # Regularization parameter\n",
        "}\n",
        "\n",
        "print(f\"Testing {len(param_grid['n_factors']) * len(param_grid['n_epochs']) * len(param_grid['lr_all']) * len(param_grid['reg_all'])} parameter combinations...\")\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search\n",
        "gs.fit(data)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nGrid Search Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Best RMSE score: {gs.best_score['rmse']:.4f}\")\n",
        "print(f\"Best MAE score: {gs.best_score['mae']:.4f}\")\n",
        "\n",
        "print(f\"\\nBest parameters (RMSE):\")\n",
        "for param, value in gs.best_params['rmse'].items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "print(f\"\\nBest parameters (MAE):\")\n",
        "for param, value in gs.best_params['mae'].items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "# Train the best model\n",
        "print(f\"\\nTraining final model with best parameters...\")\n",
        "best_algo = gs.best_estimator['rmse']\n",
        "best_algo.fit(trainset)\n",
        "\n",
        "# Test the optimized model\n",
        "optimized_predictions = best_algo.test(testset)\n",
        "optimized_rmse = accuracy.rmse(optimized_predictions, verbose=False)\n",
        "optimized_mae = accuracy.mae(optimized_predictions, verbose=False)\n",
        "\n",
        "print(f\"\\nOptimized Model Performance:\")\n",
        "print(f\"RMSE: {optimized_rmse:.4f}\")\n",
        "print(f\"MAE: {optimized_mae:.4f}\")\n",
        "\n",
        "print(f\"\\nImprovement over default SVD:\")\n",
        "print(f\"RMSE improvement: {((rmse_score - optimized_rmse) / rmse_score) * 100:.2f}%\")\n",
        "print(f\"MAE improvement: {((mae_score - optimized_mae) / mae_score) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MTPyK5qzSrz"
      },
      "source": [
        "**Exercise 1:**\n",
        "Write a code that recommends items for a users, based on a trained `surprise` model. It should sort the items by their rankings and output top N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KsbuOY5EzY8t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 1: Building recommendation system...\n",
            "Creating test set for recommendations...\n",
            "Created recommendation test set with 500 user-item pairs\n",
            "Making predictions for unrated items...\n",
            "Generating top recommendations...\n",
            "No recommendations available for user 196\n",
            "Available users for recommendations: ['211', '826', '334', '202', '155']\n",
            "\n",
            "Top 5 recommendations for user 211:\n",
            "1. Item 87: Predicted rating 3.959\n",
            "2. Item 474: Predicted rating 3.851\n",
            "3. Item 1449: Predicted rating 3.778\n",
            "4. Item 500: Predicted rating 3.709\n",
            "5. Item 742: Predicted rating 3.670\n"
          ]
        }
      ],
      "source": [
        "# Exercise 1: Item Recommendation System\n",
        "print(\"Exercise 1: Building recommendation system...\")\n",
        "\n",
        "# =========================================\n",
        "# Function to get top N recommendations for all users\n",
        "def get_top_n_recommendations(predictions, n=10):\n",
        "    \"\"\"\n",
        "    Return the top-N recommendation for each user from a set of predictions.\n",
        "    \n",
        "    Args:\n",
        "        predictions: List of predictions from surprise model\n",
        "        n: Number of recommendations to return per user\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with user_ids as keys and list of (item_id, rating) tuples as values\n",
        "    \"\"\"\n",
        "    # Initialize the top_n dict\n",
        "    top_n = {}\n",
        "    \n",
        "    # Group predictions by user\n",
        "    for prediction in predictions:\n",
        "        user_id = prediction.uid\n",
        "        item_id = prediction.iid\n",
        "        predicted_rating = prediction.est\n",
        "        \n",
        "        # Initialize user's recommendation list if not exists\n",
        "        if user_id not in top_n:\n",
        "            top_n[user_id] = []\n",
        "        \n",
        "        # Add the item and its predicted rating\n",
        "        top_n[user_id].append((item_id, predicted_rating))\n",
        "    \n",
        "    # Sort recommendations by predicted rating (descending) and keep top N\n",
        "    for user_id in top_n:\n",
        "        top_n[user_id].sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[user_id] = top_n[user_id][:n]\n",
        "    \n",
        "    return top_n\n",
        "\n",
        "# =========================================\n",
        "\n",
        "# For demonstration, let's create a test set of items that users haven't rated\n",
        "print(\"Creating test set for recommendations...\")\n",
        "\n",
        "# Get all user-item pairs that are NOT in the training set\n",
        "all_items = set([trainset.to_raw_iid(i) for i in range(trainset.n_items)])\n",
        "all_users = set([trainset.to_raw_uid(u) for u in range(trainset.n_users)])\n",
        "\n",
        "# Create test set for recommendations (items not rated by users)\n",
        "recommendation_testset = []\n",
        "sample_users = list(all_users)[:10]  # Sample first 10 users for demo\n",
        "\n",
        "for user_id in sample_users:\n",
        "    # Get items rated by this user\n",
        "    try:\n",
        "        inner_user_id = trainset.to_inner_uid(user_id)\n",
        "        user_items = set([trainset.to_raw_iid(i) for (i, _) in trainset.ur[inner_user_id]])\n",
        "        \n",
        "        # Get items NOT rated by this user\n",
        "        unrated_items = all_items - user_items\n",
        "        \n",
        "        # Sample some unrated items for prediction\n",
        "        import random\n",
        "        random.seed(42)\n",
        "        sample_items = random.sample(list(unrated_items), min(50, len(unrated_items)))\n",
        "        \n",
        "        for item_id in sample_items:\n",
        "            recommendation_testset.append((user_id, item_id, 0))  # 0 is dummy rating\n",
        "            \n",
        "    except ValueError:\n",
        "        continue\n",
        "\n",
        "print(f\"Created recommendation test set with {len(recommendation_testset)} user-item pairs\")\n",
        "\n",
        "# Get predictions for unrated items\n",
        "print(\"Making predictions for unrated items...\")\n",
        "rec_predictions = algo.test(recommendation_testset)\n",
        "\n",
        "# Get top 5 recommendations\n",
        "print(\"Generating top recommendations...\")\n",
        "top_n = get_top_n_recommendations(rec_predictions, n=5)\n",
        "\n",
        "# Display recommendations for a sample user\n",
        "sample_user = '196'\n",
        "if sample_user in top_n:\n",
        "    print(f\"\\nTop 5 recommendations for user {sample_user}:\")\n",
        "    for i, (item_id, rating) in enumerate(top_n[sample_user], 1):\n",
        "        print(f\"{i}. Item {item_id}: Predicted rating {rating:.3f}\")\n",
        "else:\n",
        "    print(f\"No recommendations available for user {sample_user}\")\n",
        "    # Show available users\n",
        "    available_users = list(top_n.keys())[:5]\n",
        "    print(f\"Available users for recommendations: {available_users}\")\n",
        "    if available_users:\n",
        "        sample_user = available_users[0]\n",
        "        print(f\"\\nTop 5 recommendations for user {sample_user}:\")\n",
        "        for i, (item_id, rating) in enumerate(top_n[sample_user], 1):\n",
        "            print(f\"{i}. Item {item_id}: Predicted rating {rating:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPpol6VG3YgV"
      },
      "source": [
        "**Exercise 2** - Address the cold start problem by recommending new users most popular items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6KN-v9hdz-Cu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 2: Addressing Cold Start Problem...\n",
            "Dataset shape: (100000, 4)\n",
            "Rating distribution:\n",
            "rating\n",
            "1.0     6110\n",
            "2.0    11370\n",
            "3.0    27145\n",
            "4.0    34174\n",
            "5.0    21201\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Calculating item popularity metrics...\n",
            "\n",
            "Item statistics (top 10 most popular):\n",
            "         rating_count  avg_rating  rating_std  unique_users  popularity_score\n",
            "item_id                                                                      \n",
            "50                583       4.358       0.881           583         27.760028\n",
            "100               508       4.156       0.976           508         25.902054\n",
            "127               413       4.283       0.935           413         25.808784\n",
            "174               420       4.252       0.892           420         25.693275\n",
            "98                390       4.290       0.837           390         25.605755\n",
            "318               298       4.466       0.829           298         25.458181\n",
            "64                283       4.445       0.767           283         25.109690\n",
            "181               507       4.008       0.924           507         24.971770\n",
            "313               350       4.246       0.947           350         24.884898\n",
            "172               367       4.204       0.923           367         24.837581\n",
            "\n",
            "Top 10 Popular Items for Cold Start Users:\n",
            "------------------------------------------------------------\n",
            " 1. Item 50: Avg Rating 4.36 (583.0 ratings)\n",
            " 2. Item 100: Avg Rating 4.16 (508.0 ratings)\n",
            " 3. Item 127: Avg Rating 4.28 (413.0 ratings)\n",
            " 4. Item 174: Avg Rating 4.25 (420.0 ratings)\n",
            " 5. Item 98: Avg Rating 4.29 (390.0 ratings)\n",
            " 6. Item 318: Avg Rating 4.47 (298.0 ratings)\n",
            " 7. Item 64: Avg Rating 4.45 (283.0 ratings)\n",
            " 8. Item 181: Avg Rating 4.01 (507.0 ratings)\n",
            " 9. Item 313: Avg Rating 4.25 (350.0 ratings)\n",
            "10. Item 172: Avg Rating 4.20 (367.0 ratings)\n",
            "\n",
            "Cold Start Recommendation Strategies:\n",
            "==================================================\n",
            "Strategy 1 - Most Popular Items:\n",
            "  1. Item 50: 4.36 stars (583.0 ratings)\n",
            "  2. Item 100: 4.16 stars (508.0 ratings)\n",
            "  3. Item 127: 4.28 stars (413.0 ratings)\n",
            "  4. Item 174: 4.25 stars (420.0 ratings)\n",
            "  5. Item 98: 4.29 stars (390.0 ratings)\n",
            "\n",
            "Strategy 2 - Diverse Popular Items:\n",
            "  1. Item 50: 4.36 stars (583.0 ratings)\n",
            "  2. Item 100: 4.16 stars (508.0 ratings)\n",
            "  3. Item 1: 3.88 stars (452.0 ratings)\n",
            "  4. Item 258: 3.80 stars (509.0 ratings)\n",
            "  5. Item 210: 3.93 stars (331.0 ratings)\n",
            "\n",
            "Cold start recommendations can be updated as the user provides more ratings!\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2: Cold Start Problem - Popular Items Recommendation\n",
        "print(\"Exercise 2: Addressing Cold Start Problem...\")\n",
        "\n",
        "# Convert the raw ratings to a pandas DataFrame for easier manipulation\n",
        "df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Rating distribution:\")\n",
        "print(df['rating'].value_counts().sort_index())\n",
        "\n",
        "# =========================================\n",
        "# Calculate popularity metrics for each item\n",
        "print(\"\\nCalculating item popularity metrics...\")\n",
        "\n",
        "# Calculate multiple popularity metrics\n",
        "item_stats = df.groupby('item_id').agg({\n",
        "    'rating': ['count', 'mean', 'std'],\n",
        "    'user_id': 'nunique'\n",
        "}).round(3)\n",
        "\n",
        "# Flatten column names\n",
        "item_stats.columns = ['rating_count', 'avg_rating', 'rating_std', 'unique_users']\n",
        "\n",
        "# Calculate popularity score (combination of rating count and average rating)\n",
        "# We weight by number of ratings to avoid items with few but high ratings\n",
        "min_ratings = 50  # Minimum number of ratings to be considered popular\n",
        "item_stats['popularity_score'] = (\n",
        "    item_stats['avg_rating'] * np.log(item_stats['rating_count'] + 1) * \n",
        "    (item_stats['rating_count'] >= min_ratings)\n",
        ")\n",
        "\n",
        "# Sort by popularity score\n",
        "item_stats = item_stats.sort_values('popularity_score', ascending=False)\n",
        "\n",
        "print(f\"\\nItem statistics (top 10 most popular):\")\n",
        "print(item_stats.head(10))\n",
        "\n",
        "# Get top N popular items for cold start recommendations\n",
        "def get_popular_items(n=10):\n",
        "    \"\"\"\n",
        "    Get the most popular items for cold start recommendations\n",
        "    \n",
        "    Args:\n",
        "        n: Number of popular items to return\n",
        "    \n",
        "    Returns:\n",
        "        List of (item_id, avg_rating, rating_count) tuples\n",
        "    \"\"\"\n",
        "    popular_items = item_stats.head(n)\n",
        "    return [(item_id, row['avg_rating'], row['rating_count']) \n",
        "            for item_id, row in popular_items.iterrows()]\n",
        "\n",
        "# Get top 10 popular items\n",
        "top_popular_items = get_popular_items(10)\n",
        "\n",
        "print(f\"\\nTop 10 Popular Items for Cold Start Users:\")\n",
        "print(\"-\" * 60)\n",
        "for i, (item_id, avg_rating, count) in enumerate(top_popular_items, 1):\n",
        "    print(f\"{i:2d}. Item {item_id}: Avg Rating {avg_rating:.2f} ({count} ratings)\")\n",
        "\n",
        "# =========================================\n",
        "\n",
        "# Function to handle cold start recommendations\n",
        "def recommend_for_cold_start_user(n=5, strategy='popular'):\n",
        "    \"\"\"\n",
        "    Recommend items for a new user (cold start problem)\n",
        "    \n",
        "    Args:\n",
        "        n: Number of recommendations\n",
        "        strategy: 'popular' or 'diverse'\n",
        "    \n",
        "    Returns:\n",
        "        List of recommended item IDs\n",
        "    \"\"\"\n",
        "    if strategy == 'popular':\n",
        "        # Simply return most popular items\n",
        "        return [item_id for item_id, _, _ in get_popular_items(n)]\n",
        "    \n",
        "    elif strategy == 'diverse':\n",
        "        # Return popular items from different rating ranges\n",
        "        high_rated = item_stats[item_stats['avg_rating'] >= 4.0].head(n//2)\n",
        "        medium_rated = item_stats[\n",
        "            (item_stats['avg_rating'] >= 3.5) & \n",
        "            (item_stats['avg_rating'] < 4.0)\n",
        "        ].head(n - len(high_rated))\n",
        "        \n",
        "        diverse_items = list(high_rated.index) + list(medium_rated.index)\n",
        "        return diverse_items[:n]\n",
        "\n",
        "# Demonstrate cold start recommendations\n",
        "print(f\"\\nCold Start Recommendation Strategies:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Strategy 1: Most popular items\n",
        "popular_recs = recommend_for_cold_start_user(5, 'popular')\n",
        "print(f\"Strategy 1 - Most Popular Items:\")\n",
        "for i, item_id in enumerate(popular_recs, 1):\n",
        "    item_info = item_stats.loc[item_id]\n",
        "    print(f\"  {i}. Item {item_id}: {item_info['avg_rating']:.2f} stars ({item_info['rating_count']} ratings)\")\n",
        "\n",
        "# Strategy 2: Diverse popular items\n",
        "diverse_recs = recommend_for_cold_start_user(5, 'diverse')\n",
        "print(f\"\\nStrategy 2 - Diverse Popular Items:\")\n",
        "for i, item_id in enumerate(diverse_recs, 1):\n",
        "    item_info = item_stats.loc[item_id]\n",
        "    print(f\"  {i}. Item {item_id}: {item_info['avg_rating']:.2f} stars ({item_info['rating_count']} ratings)\")\n",
        "\n",
        "print(f\"\\nCold start recommendations can be updated as the user provides more ratings!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0SRq9Gu4dbN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPCprSRw64e0"
      },
      "source": [
        "**Exercise 3** - Load the Amazon Product reviews dataset\n",
        "https://www.kaggle.com/datasets/saurav9786/amazon-product-reviews?resource=download using `surprise` .\n",
        "Split it into train and test instances.\n",
        "\n",
        "Find the best algorithm by using cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2koszE6dhGt1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 3: Amazon Product Reviews Analysis\n",
            "Amazon dataset not found at ratings_Electronics (1).csv\n",
            "Please download the dataset from:\n",
            "https://www.kaggle.com/datasets/saurav9786/amazon-product-reviews\n",
            "And place it in the same directory as this notebook.\n",
            "\n",
            "For now, we'll use the MovieLens dataset for demonstration...\n",
            "\n",
            "Using MovieLens dataset for algorithm comparison...\n",
            "\n",
            "Evaluating SVD on MovieLens...\n",
            "  RMSE: 0.9452 (+/- 0.0018)\n",
            "  MAE:  0.7458 (+/- 0.0020)\n",
            "\n",
            "Evaluating NMF on MovieLens...\n",
            "  RMSE: 0.9746 (+/- 0.0027)\n",
            "  MAE:  0.7652 (+/- 0.0030)\n",
            "\n",
            "Evaluating KNN_User on MovieLens...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "  RMSE: 0.9883 (+/- 0.0017)\n",
            "  MAE:  0.7811 (+/- 0.0020)\n",
            "\n",
            "Evaluating KNN_Item on MovieLens...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "  RMSE: 0.9858 (+/- 0.0038)\n",
            "  MAE:  0.7804 (+/- 0.0019)\n",
            "\n",
            "Best Algorithm: SVD\n",
            "Best RMSE: 0.9452\n",
            "Best MAE: 0.7458\n"
          ]
        }
      ],
      "source": [
        "# Exercise 3: Amazon Product Reviews Dataset\n",
        "print(\"Exercise 3: Amazon Product Reviews Analysis\")\n",
        "\n",
        "# Note: This exercise requires the Amazon dataset to be downloaded\n",
        "# Download from: https://www.kaggle.com/datasets/saurav9786/amazon-product-reviews\n",
        "# Place the CSV file in the same directory as this notebook\n",
        "\n",
        "file_path = 'ratings_Electronics (1).csv'\n",
        "\n",
        "# Check if file exists\n",
        "import os\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"Loading Amazon dataset from {file_path}\")\n",
        "    \n",
        "    # Load the dataset\n",
        "    # Assuming the CSV has columns: user_id, product_id, rating, timestamp\n",
        "    df_amazon = pd.read_csv(file_path, header=None, names=['user_id', 'product_id', 'rating', 'timestamp'])\n",
        "    \n",
        "    print(f\"Dataset shape: {df_amazon.shape}\")\n",
        "    print(f\"Dataset info:\")\n",
        "    print(df_amazon.info())\n",
        "    \n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_amazon.head())\n",
        "    \n",
        "    print(f\"\\nRating distribution:\")\n",
        "    print(df_amazon['rating'].value_counts().sort_index())\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(f\"\\nDataset Statistics:\")\n",
        "    print(f\"Number of users: {df_amazon['user_id'].nunique():,}\")\n",
        "    print(f\"Number of products: {df_amazon['product_id'].nunique():,}\")\n",
        "    print(f\"Number of ratings: {len(df_amazon):,}\")\n",
        "    print(f\"Average rating: {df_amazon['rating'].mean():.2f}\")\n",
        "    print(f\"Rating range: {df_amazon['rating'].min()} - {df_amazon['rating'].max()}\")\n",
        "    \n",
        "    # Sparsity calculation\n",
        "    n_users_amz = df_amazon['user_id'].nunique()\n",
        "    n_items_amz = df_amazon['product_id'].nunique()\n",
        "    n_ratings_amz = len(df_amazon)\n",
        "    sparsity = (1 - n_ratings_amz / (n_users_amz * n_items_amz)) * 100\n",
        "    print(f\"Sparsity: {sparsity:.2f}%\")\n",
        "    \n",
        "    # Prepare data for Surprise\n",
        "    print(f\"\\nPreparing data for Surprise library...\")\n",
        "    \n",
        "    # Create a Reader object\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    \n",
        "    # Load data into Surprise format\n",
        "    amazon_data = Dataset.load_from_df(df_amazon[['user_id', 'product_id', 'rating']], reader)\n",
        "    \n",
        "    # Split the data\n",
        "    amazon_trainset, amazon_testset = train_test_split(amazon_data, test_size=0.2, random_state=42)\n",
        "    \n",
        "    print(f\"Training set size: {len(amazon_trainset)}\")\n",
        "    print(f\"Test set size: {len(amazon_testset)}\")\n",
        "    \n",
        "    # Test different algorithms\n",
        "    print(f\"\\nTesting different algorithms with cross-validation...\")\n",
        "    \n",
        "    algorithms = {\n",
        "        'SVD': SVD(random_state=42),\n",
        "        'NMF': NMF(random_state=42),\n",
        "        'KNN_User': KNNBasic(sim_options={'user_based': True}, random_state=42),\n",
        "        'KNN_Item': KNNBasic(sim_options={'user_based': False}, random_state=42)\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for name, algorithm in algorithms.items():\n",
        "        print(f\"\\nEvaluating {name}...\")\n",
        "        \n",
        "        # Perform cross-validation\n",
        "        cv_results = cross_validate(algorithm, amazon_data, measures=['RMSE', 'MAE'], cv=3, verbose=False)\n",
        "        \n",
        "        results[name] = {\n",
        "            'RMSE': cv_results['test_rmse'].mean(),\n",
        "            'RMSE_std': cv_results['test_rmse'].std(),\n",
        "            'MAE': cv_results['test_mae'].mean(),\n",
        "            'MAE_std': cv_results['test_mae'].std()\n",
        "        }\n",
        "        \n",
        "        print(f\"  RMSE: {results[name]['RMSE']:.4f} (+/- {results[name]['RMSE_std']:.4f})\")\n",
        "        print(f\"  MAE:  {results[name]['MAE']:.4f} (+/- {results[name]['MAE_std']:.4f})\")\n",
        "    \n",
        "    # Find the best algorithm\n",
        "    best_algorithm = min(results.keys(), key=lambda x: results[x]['RMSE'])\n",
        "    \n",
        "    print(f\"\\nBest Algorithm: {best_algorithm}\")\n",
        "    print(f\"Best RMSE: {results[best_algorithm]['RMSE']:.4f}\")\n",
        "    print(f\"Best MAE: {results[best_algorithm]['MAE']:.4f}\")\n",
        "    \n",
        "    # Train the best algorithm on full training set\n",
        "    print(f\"\\nTraining {best_algorithm} on full training set...\")\n",
        "    best_algo = algorithms[best_algorithm]\n",
        "    best_algo.fit(amazon_trainset)\n",
        "    \n",
        "    # Test on test set\n",
        "    final_predictions = best_algo.test(amazon_testset)\n",
        "    final_rmse = accuracy.rmse(final_predictions, verbose=False)\n",
        "    final_mae = accuracy.mae(final_predictions, verbose=False)\n",
        "    \n",
        "    print(f\"Final test results:\")\n",
        "    print(f\"RMSE: {final_rmse:.4f}\")\n",
        "    print(f\"MAE: {final_mae:.4f}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"Amazon dataset not found at {file_path}\")\n",
        "    print(\"Please download the dataset from:\")\n",
        "    print(\"https://www.kaggle.com/datasets/saurav9786/amazon-product-reviews\")\n",
        "    print(\"And place it in the same directory as this notebook.\")\n",
        "    print(\"\\nFor now, we'll use the MovieLens dataset for demonstration...\")\n",
        "    \n",
        "    # Fallback to MovieLens for demonstration\n",
        "    print(\"\\nUsing MovieLens dataset for algorithm comparison...\")\n",
        "    \n",
        "    algorithms = {\n",
        "        'SVD': SVD(random_state=42),\n",
        "        'NMF': NMF(random_state=42),\n",
        "        'KNN_User': KNNBasic(sim_options={'user_based': True}, random_state=42),\n",
        "        'KNN_Item': KNNBasic(sim_options={'user_based': False}, random_state=42)\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for name, algorithm in algorithms.items():\n",
        "        print(f\"\\nEvaluating {name} on MovieLens...\")\n",
        "        \n",
        "        # Perform cross-validation\n",
        "        cv_results = cross_validate(algorithm, data, measures=['RMSE', 'MAE'], cv=3, verbose=False)\n",
        "        \n",
        "        results[name] = {\n",
        "            'RMSE': cv_results['test_rmse'].mean(),\n",
        "            'RMSE_std': cv_results['test_rmse'].std(),\n",
        "            'MAE': cv_results['test_mae'].mean(),\n",
        "            'MAE_std': cv_results['test_mae'].std()\n",
        "        }\n",
        "        \n",
        "        print(f\"  RMSE: {results[name]['RMSE']:.4f} (+/- {results[name]['RMSE_std']:.4f})\")\n",
        "        print(f\"  MAE:  {results[name]['MAE']:.4f} (+/- {results[name]['MAE_std']:.4f})\")\n",
        "    \n",
        "    # Find the best algorithm\n",
        "    best_algorithm = min(results.keys(), key=lambda x: results[x]['RMSE'])\n",
        "    \n",
        "    print(f\"\\nBest Algorithm: {best_algorithm}\")\n",
        "    print(f\"Best RMSE: {results[best_algorithm]['RMSE']:.4f}\")\n",
        "    print(f\"Best MAE: {results[best_algorithm]['MAE']:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAfr0cOp3TFt"
      },
      "source": [
        "**Exercise 4** - Convert the ratings matrix to implicit feedback matrix by changing all positive ratings to 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tEOdg0tI6_xH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 4: Converting to Implicit Feedback Matrix\n",
            "Converting explicit feedback to implicit feedback...\n",
            "Original matrix statistics:\n",
            "  Shape: (943, 1682)\n",
            "  Non-zero entries: 100,000\n",
            "  Rating range: 1.0 - 5.0\n",
            "\n",
            "Implicit matrix statistics:\n",
            "  Shape: (943, 1682)\n",
            "  Non-zero entries: 100,000\n",
            "  All values are now: [1.]\n",
            "\n",
            "Comparison of first 10x10 portion:\n",
            "Original ratings matrix:\n",
            "[[3. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 3. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 3. 0. 4. 0.]\n",
            " [0. 0. 0. 2. 0. 0. 4. 0. 4. 4.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 4. 4. 4. 0. 0.]\n",
            " [0. 4. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 5. 0. 0.]\n",
            " [5. 4. 0. 0. 0. 5. 0. 0. 3. 4.]\n",
            " [4. 4. 0. 0. 0. 5. 0. 1. 0. 3.]]\n",
            "\n",
            "Implicit feedback matrix (1 = interaction, 0 = no interaction):\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 1. 0. 1. 0. 1.]]\n",
            "\n",
            "User interaction statistics:\n",
            "  Average interactions per user: 106.04\n",
            "  Min interactions per user: 20.0\n",
            "  Max interactions per user: 737.0\n",
            "\n",
            "Item interaction statistics:\n",
            "  Average interactions per item: 59.45\n",
            "  Min interactions per item: 1.0\n",
            "  Max interactions per item: 583.0\n",
            "\n",
            "Implicit feedback matrix is ready for use with models like EASE!\n"
          ]
        }
      ],
      "source": [
        "# Exercise 4: Convert to Implicit Feedback Matrix\n",
        "print(\"Exercise 4: Converting to Implicit Feedback Matrix\")\n",
        "\n",
        "# Convert explicit ratings to implicit feedback\n",
        "# All positive ratings (>= 1) become 1, indicating the user interacted with the item\n",
        "print(\"Converting explicit feedback to implicit feedback...\")\n",
        "\n",
        "# Create implicit feedback matrix from the original interaction matrix\n",
        "implicit_interaction_matrix = interaction_matrix.copy()\n",
        "\n",
        "# Convert all non-zero ratings to 1 (indicating interaction)\n",
        "implicit_interaction_matrix.data = np.ones_like(implicit_interaction_matrix.data)\n",
        "\n",
        "print(f\"Original matrix statistics:\")\n",
        "print(f\"  Shape: {interaction_matrix.shape}\")\n",
        "print(f\"  Non-zero entries: {interaction_matrix.nnz:,}\")\n",
        "print(f\"  Rating range: {interaction_matrix.data.min():.1f} - {interaction_matrix.data.max():.1f}\")\n",
        "\n",
        "print(f\"\\nImplicit matrix statistics:\")\n",
        "print(f\"  Shape: {implicit_interaction_matrix.shape}\")\n",
        "print(f\"  Non-zero entries: {implicit_interaction_matrix.nnz:,}\")\n",
        "print(f\"  All values are now: {np.unique(implicit_interaction_matrix.data)}\")\n",
        "\n",
        "# Display comparison of a small portion\n",
        "print(f\"\\nComparison of first 10x10 portion:\")\n",
        "print(\"Original ratings matrix:\")\n",
        "print(interaction_matrix[:10, :10].toarray())\n",
        "\n",
        "print(\"\\nImplicit feedback matrix (1 = interaction, 0 = no interaction):\")\n",
        "print(implicit_interaction_matrix[:10, :10].toarray())\n",
        "\n",
        "# Statistics about user interactions\n",
        "user_interactions = np.array(implicit_interaction_matrix.sum(axis=1)).flatten()\n",
        "item_interactions = np.array(implicit_interaction_matrix.sum(axis=0)).flatten()\n",
        "\n",
        "print(f\"\\nUser interaction statistics:\")\n",
        "print(f\"  Average interactions per user: {user_interactions.mean():.2f}\")\n",
        "print(f\"  Min interactions per user: {user_interactions.min()}\")\n",
        "print(f\"  Max interactions per user: {user_interactions.max()}\")\n",
        "\n",
        "print(f\"\\nItem interaction statistics:\")\n",
        "print(f\"  Average interactions per item: {item_interactions.mean():.2f}\")\n",
        "print(f\"  Min interactions per item: {item_interactions.min()}\")\n",
        "print(f\"  Max interactions per item: {item_interactions.max()}\")\n",
        "\n",
        "print(f\"\\nImplicit feedback matrix is ready for use with models like EASE!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kRBA0GX24h9"
      },
      "source": [
        "**Exercise 5** - Read the EASE model paper (https://arxiv.org/abs/1905.03375).\n",
        "Implement the algorithm in the paper and apply it on the *implicit feedback matrix* of ml-100k to recommend items to users.\n",
        "Write two parts -\n",
        " *Training* in which the model matrix is created\n",
        " *Inference* in which the interaction scores per user are predicted\n",
        "\n",
        "Hints:\n",
        "---\n",
        "Training:\n",
        "- Start with computing the Gram matrix\n",
        "- Add lambda regularization to the diagonal as described in the paper\n",
        "- Compute the inverse and find the item-item interaction matrix,\n",
        "- Zero the diagonal indexes\n",
        "\n",
        "Inference:\n",
        "- Multiply the user interaction matrix by the item-item interaction matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yE0LXCFA3SST"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exercise 5: Implementing EASE (Embarrassingly Shallow Autoencoders)\n",
            "Based on the paper: https://arxiv.org/abs/1905.03375\n",
            "\n",
            "============================================================\n",
            "Training EASE Model on MovieLens Implicit Feedback Data\n",
            "============================================================\n",
            "Training EASE model with lambda_reg=0.5\n",
            "Step 1: Computing Gram matrix...\n",
            "Gram matrix shape: (1682, 1682)\n",
            "Gram matrix density: 69.57%\n",
            "Step 2: Adding regularization to diagonal...\n",
            "Step 3: Computing matrix inverse...\n",
            "Step 4: Computing item-item similarity matrix...\n",
            "Step 5: Zeroing diagonal elements...\n",
            "EASE model training completed!\n",
            "Similarity matrix statistics:\n",
            "  Shape: (1682, 1682)\n",
            "  Non-zero elements: 2,827,442\n",
            "  Density: 99.94%\n",
            "  Value range: -0.6413 to 0.6978\n",
            "\n",
            "Generating predictions for all users...\n",
            "Generating predictions...\n",
            "Predictions shape: (943, 1682)\n",
            "Prediction range: -0.4658 to 1.3482\n",
            "\n",
            "Generating recommendations for User 0:\n",
            "Generating predictions...\n",
            "Predictions shape: (943, 1682)\n",
            "Prediction range: -0.4658 to 1.3482\n",
            "Top 10 recommendations for User 0:\n",
            "----------------------------------------\n",
            " 1. Item 209: Score 0.1079\n",
            " 2. Item 404: Score 0.0966\n",
            " 3. Item 189: Score 0.0795\n",
            " 4. Item  47: Score 0.0686\n",
            " 5. Item  52: Score 0.0675\n",
            " 6. Item  43: Score 0.0673\n",
            " 7. Item 614: Score 0.0596\n",
            " 8. Item 356: Score 0.0555\n",
            " 9. Item 243: Score 0.0550\n",
            "10. Item 247: Score 0.0545\n",
            "\n",
            "Items User 0 has already interacted with:\n",
            "Total items: 39\n",
            "Item IDs: [0, 10, 83, 86, 92, 179, 221, 289, 291, 302]...\n",
            "\n",
            "Model Evaluation:\n",
            "Total trainable parameters: 0 (closed-form solution)\n",
            "Item-item similarity matrix size: 1682 x 1682\n",
            "Memory usage: ~21.58 MB\n",
            "\n",
            "EASE model successfully implemented and tested!\n",
            "The model can now be used for real-time recommendations.\n"
          ]
        }
      ],
      "source": [
        "# Exercise 5: EASE Model Implementation\n",
        "print(\"Exercise 5: Implementing EASE (Embarrassingly Shallow Autoencoders)\")\n",
        "print(\"Based on the paper: https://arxiv.org/abs/1905.03375\")\n",
        "\n",
        "class EASE:\n",
        "    \"\"\"\n",
        "    EASE (Embarrassingly Shallow Autoencoders for Sparse Data) Implementation\n",
        "    \n",
        "    This model learns item-item similarities through a closed-form solution\n",
        "    that can be computed efficiently using matrix operations.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, lambda_reg=0.5):\n",
        "        \"\"\"\n",
        "        Initialize EASE model\n",
        "        \n",
        "        Args:\n",
        "            lambda_reg: Regularization parameter (lambda in the paper)\n",
        "        \"\"\"\n",
        "        self.lambda_reg = lambda_reg\n",
        "        self.B = None  # Item-item similarity matrix\n",
        "        self.trained = False\n",
        "        \n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Train the EASE model\n",
        "        \n",
        "        Args:\n",
        "            X: User-item interaction matrix (users x items)\n",
        "               Should be in implicit feedback format (0s and 1s)\n",
        "        \"\"\"\n",
        "        print(f\"Training EASE model with lambda_reg={self.lambda_reg}\")\n",
        "        \n",
        "        # Step 1: Compute the Gram matrix (X^T * X)\n",
        "        print(\"Step 1: Computing Gram matrix...\")\n",
        "        X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
        "        G = X_dense.T @ X_dense  # Item-item co-occurrence matrix\n",
        "        \n",
        "        print(f\"Gram matrix shape: {G.shape}\")\n",
        "        print(f\"Gram matrix density: {np.count_nonzero(G) / G.size * 100:.2f}%\")\n",
        "        \n",
        "        # Step 2: Add regularization to diagonal\n",
        "        print(\"Step 2: Adding regularization to diagonal...\")\n",
        "        np.fill_diagonal(G, G.diagonal() + self.lambda_reg)\n",
        "        \n",
        "        # Step 3: Compute the inverse\n",
        "        print(\"Step 3: Computing matrix inverse...\")\n",
        "        try:\n",
        "            G_inv = np.linalg.inv(G)\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(\"Matrix is singular, using pseudo-inverse...\")\n",
        "            G_inv = np.linalg.pinv(G)\n",
        "        \n",
        "        # Step 4: Compute item-item similarity matrix B\n",
        "        print(\"Step 4: Computing item-item similarity matrix...\")\n",
        "        self.B = G_inv / (-np.diag(G_inv))\n",
        "        \n",
        "        # Step 5: Zero out the diagonal (items don't recommend themselves)\n",
        "        print(\"Step 5: Zeroing diagonal elements...\")\n",
        "        np.fill_diagonal(self.B, 0.0)\n",
        "        \n",
        "        self.trained = True\n",
        "        print(\"EASE model training completed!\")\n",
        "        \n",
        "        # Print some statistics\n",
        "        print(f\"Similarity matrix statistics:\")\n",
        "        print(f\"  Shape: {self.B.shape}\")\n",
        "        print(f\"  Non-zero elements: {np.count_nonzero(self.B):,}\")\n",
        "        print(f\"  Density: {np.count_nonzero(self.B) / self.B.size * 100:.2f}%\")\n",
        "        print(f\"  Value range: {self.B.min():.4f} to {self.B.max():.4f}\")\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Generate predictions for all user-item pairs\n",
        "        \n",
        "        Args:\n",
        "            X: User-item interaction matrix (same as training)\n",
        "            \n",
        "        Returns:\n",
        "            Predicted scores matrix (users x items)\n",
        "        \"\"\"\n",
        "        if not self.trained:\n",
        "            raise ValueError(\"Model must be trained before making predictions\")\n",
        "        \n",
        "        print(\"Generating predictions...\")\n",
        "        X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
        "        \n",
        "        # Compute predictions: X * B\n",
        "        predictions = X_dense @ self.B\n",
        "        \n",
        "        print(f\"Predictions shape: {predictions.shape}\")\n",
        "        print(f\"Prediction range: {predictions.min():.4f} to {predictions.max():.4f}\")\n",
        "        \n",
        "        return predictions\n",
        "    \n",
        "    def recommend(self, X, user_id, n_recommendations=10, remove_seen=True):\n",
        "        \"\"\"\n",
        "        Get top-N recommendations for a specific user\n",
        "        \n",
        "        Args:\n",
        "            X: User-item interaction matrix\n",
        "            user_id: ID of the user (row index)\n",
        "            n_recommendations: Number of recommendations to return\n",
        "            remove_seen: Whether to remove items the user has already interacted with\n",
        "            \n",
        "        Returns:\n",
        "            List of (item_id, score) tuples sorted by score (descending)\n",
        "        \"\"\"\n",
        "        if not self.trained:\n",
        "            raise ValueError(\"Model must be trained before making recommendations\")\n",
        "        \n",
        "        # Get predictions for all items for this user\n",
        "        predictions = self.predict(X)\n",
        "        user_scores = predictions[user_id]\n",
        "        \n",
        "        # Create list of (item_id, score) pairs\n",
        "        item_scores = [(i, score) for i, score in enumerate(user_scores)]\n",
        "        \n",
        "        # Remove items the user has already interacted with\n",
        "        if remove_seen:\n",
        "            X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
        "            seen_items = set(np.where(X_dense[user_id] > 0)[0])\n",
        "            item_scores = [(i, score) for i, score in item_scores if i not in seen_items]\n",
        "        \n",
        "        # Sort by score (descending) and return top N\n",
        "        item_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return item_scores[:n_recommendations]\n",
        "\n",
        "# Train the EASE model\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training EASE Model on MovieLens Implicit Feedback Data\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize and train the model\n",
        "ease_model = EASE(lambda_reg=0.5)\n",
        "ease_model.fit(implicit_interaction_matrix)\n",
        "\n",
        "# Generate predictions\n",
        "print(\"\\nGenerating predictions for all users...\")\n",
        "ease_predictions = ease_model.predict(implicit_interaction_matrix)\n",
        "\n",
        "# Demonstrate recommendations for a sample user\n",
        "sample_user_id = 0  # First user\n",
        "print(f\"\\nGenerating recommendations for User {sample_user_id}:\")\n",
        "\n",
        "# Get recommendations\n",
        "recommendations = ease_model.recommend(\n",
        "    implicit_interaction_matrix, \n",
        "    user_id=sample_user_id, \n",
        "    n_recommendations=10,\n",
        "    remove_seen=True\n",
        ")\n",
        "\n",
        "print(f\"Top 10 recommendations for User {sample_user_id}:\")\n",
        "print(\"-\" * 40)\n",
        "for i, (item_id, score) in enumerate(recommendations, 1):\n",
        "    print(f\"{i:2d}. Item {item_id:3d}: Score {score:.4f}\")\n",
        "\n",
        "# Show what items this user has already interacted with\n",
        "user_items = np.where(implicit_interaction_matrix[sample_user_id].toarray()[0] > 0)[0]\n",
        "print(f\"\\nItems User {sample_user_id} has already interacted with:\")\n",
        "print(f\"Total items: {len(user_items)}\")\n",
        "print(f\"Item IDs: {user_items[:10].tolist()}{'...' if len(user_items) > 10 else ''}\")\n",
        "\n",
        "# Evaluation: Calculate recommendation quality\n",
        "print(f\"\\nModel Evaluation:\")\n",
        "print(f\"Total trainable parameters: 0 (closed-form solution)\")\n",
        "print(f\"Item-item similarity matrix size: {ease_model.B.shape[0]} x {ease_model.B.shape[1]}\")\n",
        "print(f\"Memory usage: ~{ease_model.B.nbytes / 1024**2:.2f} MB\")\n",
        "\n",
        "print(f\"\\nEASE model successfully implemented and tested!\")\n",
        "print(f\"The model can now be used for real-time recommendations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgerfKj96BBM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
